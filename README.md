# ğŸ•·ï¸ ScrapeThyPlaite - Advanced Web Scraping Framework

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸš€ The Most Advanced Open-Source Web Scraping Framework

ScrapeThyPlaite is an enterprise-grade web scraping framework designed for AI companies and data scientists who need reliable, ethical, and powerful data extraction capabilities. **Capable of bypassing the toughest protections including DataDome, Cloudflare, Akamai, PerimeterX, and more.**

## âœ¨ Features

### ğŸ›¡ï¸ Anti-Detection & Bypass Capabilities
- **Multi-Layer Bypass System** - Automatic strategy escalation when blocked
- **TLS Fingerprint Spoofing** - curl_cffi with JA3/JA4 fingerprint impersonation
- **DrissionPage Integration** - Undetectable browser automation with no webdriver flags
- **Playwright Stealth** - Maximum stealth with comprehensive anti-detection scripts
- **Undetected Chrome Driver** - Bypasses bot detection systems
- **Cloudflare Bypass** - Navigate through Cloudflare/Turnstile protection
- **DataDome Bypass** - Handle aggressive fingerprinting
- **Akamai/PerimeterX Bypass** - Commercial WAF bypass capabilities
- **CAPTCHA Solving** - Integration with 2Captcha, Anti-Captcha, and CapMonster
- **Browser Fingerprint Randomization** - Evade canvas, WebGL, audio fingerprinting
- **Protection Auto-Detection** - Automatically detect and respond to protection systems

### ğŸ‡®ğŸ‡± Israeli Sites Support
- **Madlan.co.il** - Real estate portal with DataDome protection
- **Yad2.co.il** - Classifieds with custom protection
- **Walla/Globes** - News sites with Cloudflare/Akamai
- Pre-configured strategies for Israeli websites

### ğŸ”„ Multi-Engine Support
- **TLS Fingerprint Engine** - curl_cffi for HTTP/2 with browser impersonation
- **DrissionPage Engine** - Chrome DevTools Protocol without webdriver detection
- **Playwright Stealth** - Async browser with comprehensive evasion
- **Ultimate Scraper** - Auto-escalating multi-strategy scraper
- **Selenium** - Full browser automation
- **Playwright** - Modern async browser automation
- **CloudScraper** - Cloudflare bypass
- **HTTPX** - Fast async HTTP client

### ğŸŒ Proxy & Network
- **Rotating Proxy Support** - Automatic proxy rotation
- **Residential Proxy Integration** - Support for premium proxy providers
- **SOCKS5/HTTP(S) Proxies** - All proxy types supported
- **Automatic Retry with Backoff** - Smart retry mechanisms

### ğŸ§  Intelligent Scraping
- **AI-Powered Content Extraction** - LLM integration for smart parsing
- **Automatic Schema Detection** - Auto-detect data structures
- **JavaScript Rendering** - Full SPA support
- **Dynamic Content Waiting** - Smart element waiting strategies

### ğŸ“Š Data Processing
- **Multiple Export Formats** - JSON, CSV, Parquet, SQLite
- **Data Validation** - Pydantic models for data integrity
- **Deduplication** - Automatic duplicate detection
- **Rate Limiting** - Respectful scraping with configurable limits

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/JackAmichai/ScrapeThyPlaite.git
cd ScrapeThyPlaite

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install
```

## ğŸš€ Quick Start

```python
from scrape_thy_plaite import Scraper, ScraperConfig

# Initialize with anti-detection
config = ScraperConfig(
    engine="undetected_chrome",
    proxy_rotation=True,
    captcha_solver="2captcha",
    respect_robots_txt=True
)

scraper = Scraper(config)

# Scrape with automatic protection bypass
data = await scraper.scrape(
    url="https://example.com",
    selectors={
        "title": "h1",
        "content": ".main-content",
        "links": "a[href]"
    }
)

print(data)
```

## ğŸ”§ Advanced Usage

### Using Different Engines

```python
# Playwright (Async, Modern)
async with PlaywrightScraper() as scraper:
    page = await scraper.new_page(stealth=True)
    await page.goto("https://example.com")
    content = await page.content()

# Undetected Chrome (Selenium-based)
with UndetectedChromeScraper() as scraper:
    scraper.get("https://example.com")
    element = scraper.find_element(By.CSS_SELECTOR, ".data")

# CloudScraper (Cloudflare bypass)
with CloudflareScraper() as scraper:
    response = scraper.get("https://cloudflare-protected-site.com")
```

### ğŸš€ NEW: Ultimate Scraper (Toughest Sites)

```python
from scrape_thy_plaite.engines import UltimateScraper, SiteSpecificScraper, BypassStrategy

# Auto-escalating scraper - tries multiple strategies until success
scraper = UltimateScraper()
await scraper.initialize()

# Automatically escalates: TLS -> CloudScraper -> Undetected Chrome -> Playwright Stealth -> DrissionPage
result = await scraper.scrape(
    "https://tough-protected-site.com",
    wait_for_selector=".content"
)

if result["success"]:
    print(f"Strategy used: {result['strategy_used']}")
    print(f"HTML length: {len(result['html'])}")
```

### ğŸ‡®ğŸ‡± Israeli Sites (Madlan, Yad2)

```python
from scrape_thy_plaite.engines import SiteSpecificScraper

# Pre-configured for Israeli site protections (DataDome, etc.)
scraper = await SiteSpecificScraper.for_israeli_sites()
await scraper.initialize()

# Scrape Madlan (DataDome protected)
result = await scraper.scrape(
    "https://www.madlan.co.il/for-sale/tel-aviv-yafo",
    wait_for_selector="div[data-testid='listing-card']"
)

# Or use specialized MadlanScraper from examples/tough_sites.py
from examples.tough_sites import MadlanScraper

async with MadlanScraper() as scraper:
    apartments = await scraper.search_apartments(
        city="tel-aviv-yafo",
        min_price=1000000,
        min_rooms=3
    )
```

### TLS Fingerprint Engine

```python
from scrape_thy_plaite.engines import TLSFingerprintEngine

# Impersonate real browser TLS fingerprints
tls_engine = TLSFingerprintEngine()
await tls_engine.initialize()

# Uses curl_cffi to perfectly mimic Chrome/Edge/Safari TLS
response = await tls_engine.get("https://tls-protected-site.com")
```

### Protection Auto-Detection

```python
from scrape_thy_plaite.stealth import detect_and_recommend

# Detect what protection a site uses
result = detect_and_recommend(
    html=response_html,
    headers=response_headers,
    cookies=response_cookies,
    status_code=403
)

print(result["protections"])  # [{"type": "datadome", "confidence": 0.9, ...}]
print(result["recommended_strategies"])  # ["drission_page", "playwright_stealth"]
```

### CAPTCHA Solving

```python
from scrape_thy_plaite.captcha import CaptchaSolver

solver = CaptchaSolver(
    provider="2captcha",
    api_key="YOUR_API_KEY"
)

# Solve reCAPTCHA v2
solution = await solver.solve_recaptcha_v2(
    site_key="6Le-wvkSAAAAAPBMRTvw0Q4Muexq9bi0DJwx_mJ-",
    page_url="https://example.com"
)

# Solve hCaptcha
solution = await solver.solve_hcaptcha(
    site_key="a5f74b19-9e45-...",
    page_url="https://example.com"
)
```

### Proxy Rotation

```python
from scrape_thy_plaite.proxy import ProxyManager

proxy_manager = ProxyManager(
    proxies=[
        "http://user:pass@proxy1.com:8080",
        "socks5://user:pass@proxy2.com:1080",
    ],
    rotation_strategy="round_robin",  # or "random", "least_used"
    health_check=True
)

scraper = Scraper(proxy_manager=proxy_manager)
```

## âš–ï¸ Legal & Ethical Use

This tool is designed for **legal and ethical** web scraping:

- âœ… Always respect `robots.txt`
- âœ… Implement rate limiting to avoid server overload
- âœ… Use for publicly available data only
- âœ… Comply with website Terms of Service
- âœ… CAPTCHA solving services are paid and legal
- âœ… Don't scrape personal/private data without consent

## ğŸ“ Project Structure

```
ScrapeThyPlaite/
â”œâ”€â”€ scrape_thy_plaite/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ selenium_engine.py
â”‚   â”‚   â”œâ”€â”€ playwright_engine.py
â”‚   â”‚   â”œâ”€â”€ undetected_chrome.py
â”‚   â”‚   â”œâ”€â”€ cloudscraper_engine.py
â”‚   â”‚   â”œâ”€â”€ httpx_engine.py
â”‚   â”‚   â”œâ”€â”€ tls_fingerprint.py      # NEW: TLS/JA3 fingerprint spoofing
â”‚   â”‚   â”œâ”€â”€ drission_engine.py      # NEW: Undetectable browser automation
â”‚   â”‚   â”œâ”€â”€ playwright_stealth.py   # NEW: Maximum stealth Playwright
â”‚   â”‚   â””â”€â”€ ultimate_scraper.py     # NEW: Multi-strategy auto-escalation
â”‚   â”œâ”€â”€ captcha/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_solver.py
â”‚   â”‚   â”œâ”€â”€ two_captcha.py
â”‚   â”‚   â”œâ”€â”€ anticaptcha.py
â”‚   â”‚   â””â”€â”€ capmonster.py
â”‚   â”œâ”€â”€ proxy/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â””â”€â”€ providers.py
â”‚   â”œâ”€â”€ stealth/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fingerprint.py
â”‚   â”‚   â”œâ”€â”€ headers.py
â”‚   â”‚   â”œâ”€â”€ evasion.py
â”‚   â”‚   â””â”€â”€ antibot_detection.py    # NEW: Protection detection system
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ css_extractor.py
â”‚   â”‚   â”œâ”€â”€ xpath_extractor.py
â”‚   â”‚   â””â”€â”€ ai_extractor.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ retry.py
â”‚       â”œâ”€â”€ rate_limiter.py
â”‚       â””â”€â”€ export.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_scraping.py
â”‚   â”œâ”€â”€ cloudflare_bypass.py
â”‚   â”œâ”€â”€ captcha_solving.py
â”‚   â”œâ”€â”€ proxy_rotation.py
â”‚   â””â”€â”€ tough_sites.py              # NEW: Madlan, Yad2, protected sites
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines.

## ğŸ“„ License

MIT License - see LICENSE file for details.

## âš ï¸ Disclaimer

This tool is for educational and legitimate business purposes only. Users are responsible for ensuring their use complies with applicable laws and website terms of service.
